{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from contextlib import redirect_stderr\n",
    "import numpy as np\n",
    "from numpy.lib.ufunclike import _fix_and_maybe_deprecate_out_named_y\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def load_dataset(path=\"data/rent-ideal.csv\"):\n",
    "    dataset = np.loadtxt(path, delimiter=\",\", skiprows=1)\n",
    "    y = dataset[:, -1]\n",
    "    X = dataset[:, 0:- 1]\n",
    "    return X, y\n",
    "\n",
    "def gradient_boosting_mse(X, y, num_iter, max_depth=1, nu=0.1):\n",
    "    \"\"\"Given X, a array y and num_iter return y_mean and trees \n",
    "   \n",
    "    Input: X, y, num_iter\n",
    "           max_depth\n",
    "           nu (is the shinkage)\n",
    "    Outputs:y_mean, array of trees from DecisionTreeRegression\n",
    "    \"\"\"\n",
    "    trees = []\n",
    "    N, _ = X.shape\n",
    "    y_mean = np.mean(y) # intialize the f0(x)\n",
    "    fm = y_mean.repeat(len(X))       # m = 0 -> f0\n",
    "    for m in range(0,num_iter):\n",
    "        residual = y - fm \n",
    "        Tm = DecisionTreeRegressor(max_depth=max_depth)\n",
    "        Tm.fit(X=X, y=residual)\n",
    "        trees.append(Tm)\n",
    "        # learning rate should be applied on iutput of stump\n",
    "        fm = fm + nu*Tm.predict(X)\n",
    "    return y_mean, trees  \n",
    "\n",
    "def gradient_boosting_predict(X, trees, y_mean,  nu=0.1):\n",
    "    \"\"\"Given X, trees, y_mean predict y_hat\n",
    "    \"\"\"\n",
    "    yhat = np.array(y_mean.repeat(len(X)))\n",
    "    for t in trees:\n",
    "        yhat = yhat + nu*t.predict(X)\n",
    "\n",
    "    return yhat"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}